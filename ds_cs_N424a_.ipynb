{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ds-cs-N424a_.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grayfactory/ProjectSc3-MovieRec/blob/master/ds_cs_N424a_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzaaHL75OF2K"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / Assignment 4*\n",
        "\n",
        "---\n",
        "# N414. 신경망과 학습에 관련된 파라미터 튜닝 (HyperTune)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ryp-TVm4njD"
      },
      "source": [
        "\n",
        "\n",
        "## 실전 연습과제\n",
        "\n",
        "다음 통신사 고객 이탈(Churn) 데이터셋에서 정확도를 조정해보는 파라미터 학습을 진행해보겠습니다 : [다운로드](https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/telecom/TelcomCustomer.csv)\n",
        "\n",
        "## 진행방식\n",
        "\n",
        "- 데이터를 다운로드 받고 읽어옴(load)\n",
        "- 데이터 클리닝을 진행 (필수는 아니지만 추천)\n",
        "- Keras MLP model을 만들고, 학습 진행\n",
        "- Hyperparameter 튜닝 진행:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (optimizer에 따라서 해당되면)\n",
        " - momentum (optimizer에 따라서 해당되면)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        "하이퍼 파라미터의 초기 패스를 위해 그리드 검색 및 교차 검증을 사용할 수 있어야 합니다. \n",
        "\n",
        "실제 큰 통신회사의 데이터이기 때문에 최대한 정확하게 파악해 보십시오! \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j68yxJGopANf"
      },
      "source": [
        "# 데이터 전처리 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB91n40ySJxC"
      },
      "source": [
        "### 문항 1) 내 로컬 파일을 colab에 업로드하기\n",
        "\n",
        "충분한 GPU를 가지고 있다면, 쉽게 문제를 해결할 수 있겠지만, 제한된 자원에서 충분한 GPU를 제공받지 못할 지 모릅니다. 이럴 때에는 딥러닝 커뮤니티에 물어볼 수도 있겠지만, 가성비 좋은 Colab의 GPU를 이용해서 실제 GPU사용량을 예측할 수 있다면 좋겠습니다. 모델 파라미터의 개수와 batch size 등이 GPU메모리에 큰 영향을 미치니 여러가지로 활용해보시기 바랍니다.\n",
        "\n",
        "Colab의 GPU를 이용하기 위해서, 로컬로 진행하시던 분들도 이번에는 colab을 사용해봅시다. \n",
        "\n",
        "- 구글에서 colab의 라이브러리를 찾아서 업로드하세요. \n",
        "이후에 Pandas를 이용하여 데이터프레임으로 저장합니다.\n",
        "\n",
        "colab을 사용하기위해서는 colab 라이브러리들을 잘 활용할 수 있으면 좋습니다. colab 기본형의 GPU의 사용제한 때문에 하지 못하는 일이 있다면, colab pro를 사용할 수 있습니다. 코드스테이츠에서 제공하는 colab pro 설치 가이드가 있지만, 스스로 문제를 해결해보시면 좋습니다. 그러나 도움이 필요하시면 HelpDesk에 문의해주시기 바랍니다.\n",
        "\n",
        "### 로컬 파일을 업로드하는 코드를 입력하세요. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCcmHvWFXOQQ"
      },
      "source": [
        "from __future__ import print_function"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "1pmAXCZSsyKu",
        "outputId": "19d5a353-854e-487a-bcd3-4e9af5fcc334"
      },
      "source": [
        "##### Your Code Here #####\n",
        "from google.colab import files\n",
        "myfiles = files.upload()\n",
        "# 데이터 불러오기"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2bfe7d3f-9d5c-439d-8d54-68490f4c09cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2bfe7d3f-9d5c-439d-8d54-68490f4c09cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving TelcomCustomer.csv to TelcomCustomer.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJylhd0JeYO"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('TelcomCustomer.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOSklFLyJ__j",
        "outputId": "afd8c6f0-0580-4e36-fe16-31e59a4516f0"
      },
      "source": [
        "df.head()\n",
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7043, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3q777ZqUvcb"
      },
      "source": [
        "### 문항 2) 결측치가 있는지 isnull()함수를 이용하여 확인하고 결과값을 입력하시오. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRSyDmSzKJrr",
        "outputId": "5fc12fd9-2dae-4944-d713-1cdbbea22a05"
      },
      "source": [
        "import numpy as np\n",
        "##### Your Code Here #####\n",
        "# 결측치 확인\n",
        "for c in df.columns:\n",
        "  # print(c, df[c].isnull().sum())\n",
        "  print(c, df[c].replace(' ',np.nan).isnull().sum())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "customerID 0\n",
            "gender 0\n",
            "SeniorCitizen 0\n",
            "Partner 0\n",
            "Dependents 0\n",
            "tenure 0\n",
            "PhoneService 0\n",
            "MultipleLines 0\n",
            "InternetService 0\n",
            "OnlineSecurity 0\n",
            "OnlineBackup 0\n",
            "DeviceProtection 0\n",
            "TechSupport 0\n",
            "StreamingTV 0\n",
            "StreamingMovies 0\n",
            "Contract 0\n",
            "PaperlessBilling 0\n",
            "PaymentMethod 0\n",
            "MonthlyCharges 0\n",
            "TotalCharges 11\n",
            "Churn 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bnUhXpSokaa",
        "outputId": "f30da568-182e-4e55-c852-2508a376b7d0"
      },
      "source": [
        "np.nan"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL9P54f2U8Is"
      },
      "source": [
        "### 문항 3) dtypes를 이용해서 데이터 타입을 확인하고 아래 문제에 답하시오.\n",
        "\n",
        "TotalCharges와 같이 중요한 타켓값이 숫자로 되어있어야 하는데, object로 되어있는 것을 확인하고 숫자형으로 바꿔주세요. <br>\n",
        "숫자형이 아닌 결측치의 개수는 몇개인가요? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMo04PeBLUO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64229d54-9749-46ec-f22e-99c2064e94d5"
      },
      "source": [
        "##### Your Code Here #####\n",
        "# 데이터 타입 확인\n",
        "df.info()\n",
        "# TotalCharges 숫자형으로 변환\n",
        "\n",
        "# 결측치 확인\n",
        "df['TotalCharges'].replace(' ', np.nan, inplace=True)\n",
        "print('빈칸 결측치 수 :',df['TotalCharges'].isnull().sum())\n",
        "# 결측치 드랍\n",
        "df.dropna(axis=0, inplace=True)\n",
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customerID        7043 non-null   object \n",
            " 1   gender            7043 non-null   object \n",
            " 2   SeniorCitizen     7043 non-null   int64  \n",
            " 3   Partner           7043 non-null   object \n",
            " 4   Dependents        7043 non-null   object \n",
            " 5   tenure            7043 non-null   int64  \n",
            " 6   PhoneService      7043 non-null   object \n",
            " 7   MultipleLines     7043 non-null   object \n",
            " 8   InternetService   7043 non-null   object \n",
            " 9   OnlineSecurity    7043 non-null   object \n",
            " 10  OnlineBackup      7043 non-null   object \n",
            " 11  DeviceProtection  7043 non-null   object \n",
            " 12  TechSupport       7043 non-null   object \n",
            " 13  StreamingTV       7043 non-null   object \n",
            " 14  StreamingMovies   7043 non-null   object \n",
            " 15  Contract          7043 non-null   object \n",
            " 16  PaperlessBilling  7043 non-null   object \n",
            " 17  PaymentMethod     7043 non-null   object \n",
            " 18  MonthlyCharges    7043 non-null   float64\n",
            " 19  TotalCharges      7043 non-null   object \n",
            " 20  Churn             7043 non-null   object \n",
            "dtypes: float64(1), int64(2), object(18)\n",
            "memory usage: 1.1+ MB\n",
            "빈칸 결측치 수 : 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7032, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWdECRBDKWsj"
      },
      "source": [
        "# customerID 드랍\n",
        "df = df.drop(columns='customerID')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh34JsVdtw3g",
        "outputId": "da803552-f41f-4ecd-8027-388e55a66589"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7032, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT-P_VEV4s67"
      },
      "source": [
        "# Attributing No internet service to No\n",
        "no_internet_feats = [ 'TechSupport','OnlineBackup', 'DeviceProtection','StreamingTV',\n",
        "                 'OnlineSecurity','StreamingMovies']\n",
        "\n",
        "for i in no_internet_feats:\n",
        "    df[i] = df[i].replace({'No internet service':'No'})\n",
        "\n",
        "# Attributing No phone service to No\n",
        "df['MultipleLines']=df['MultipleLines'].replace({'No phone service':'No'})\n",
        "\n",
        "# Attributing No phone service to No\n",
        "df['SeniorCitizen']=df['SeniorCitizen'].replace({0:'No',\n",
        "                                                 1:'Yes'})"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlGG-AoeM0WY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b43cdd8-8f32-4fd0-f725-af211913ff6d"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 19.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "oTiY-aTKTrbY",
        "outputId": "3a505b3e-8bc2-4074-9fa6-74f0e41e31da"
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n",
              "0  Female            No     Yes  ...          29.85         29.85    No\n",
              "1    Male            No      No  ...          56.95        1889.5    No\n",
              "2    Male            No      No  ...          53.85        108.15   Yes\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8C8PGvoKW1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c142de-8310-4498-db10-4f4bc6a614c0"
      },
      "source": [
        "# 원핫 인코딩\n",
        "from category_encoders import OrdinalEncoder\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "df_encoded = encoder.fit_transform(df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "3BG1KYmSNCqr",
        "outputId": "1015d450-d583-4ef7-e327-7fc98ca2221e"
      },
      "source": [
        "df_encoded.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29.85</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>56.95</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>53.85</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>42.30</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>70.70</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender  SeniorCitizen  Partner  ...  MonthlyCharges  TotalCharges  Churn\n",
              "0       1              1        1  ...           29.85             1      1\n",
              "1       2              1        2  ...           56.95             2      1\n",
              "2       2              1        2  ...           53.85             3      2\n",
              "3       2              1        2  ...           42.30             4      1\n",
              "4       1              1        2  ...           70.70             5      2\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7bZ586RWMhm",
        "outputId": "a7894a03-7106-45e3-bb1a-6cdacc25b8b9"
      },
      "source": [
        "# 타겟을 0과 1로 바꿔주기\n",
        "df_encoded['Churn'] = df_encoded['Churn'].replace({1: 0, 2: 1})\n",
        "df_encoded['Churn'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5163\n",
              "1    1869\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cQShFbLW8zO",
        "outputId": "49821dca-9d43-415f-bc27-e97ee23f79e8"
      },
      "source": [
        "df_encoded.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7032, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO6qtHPGlUtk"
      },
      "source": [
        "### 문항 4) 훈련집합과 테스트 집합을 나누는 코드를 만들고, 해당 코드를 입력하시오.\n",
        "\n",
        "- random_state=1\n",
        "- test_size=0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfcv-kpAWJz8",
        "outputId": "071b4fcb-5cc4-44bf-98bb-2b7095867920"
      },
      "source": [
        "##### Your Code Here #####\n",
        "# 훈련, 테스트 셋을 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df_encoded, stratify=df_encoded['Churn'], random_state=1, test_size=0.25)\n",
        "train.shape, test.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5274, 20), (1758, 20))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrSGVTe_VOkF"
      },
      "source": [
        "# features 와 target 을 분리\n",
        "\n",
        "target = 'Churn'\n",
        "features = df_encoded.drop(columns=[target]).columns\n",
        "\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "\n",
        "y_train = train[target]\n",
        "y_test = test[target]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI7H5xZLmJYB"
      },
      "source": [
        "### 문항 5) sklearn.preprocessing.StandardScaler를 이용하여 정규화를 진행하시고, 문제를 보고 빈칸에 알맞은 단어를 넣으시오.\n",
        "\n",
        "`X_train_scaled = scaler.##### Your Code Here #####`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKngHITnNumF"
      },
      "source": [
        "##### Your Code Here #####\n",
        "# 정규화\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test) ##### Your Code Here #####"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMdVvfM3NuuI",
        "outputId": "5b84f2f7-15fa-48af-fe85-8787915df5d2"
      },
      "source": [
        "# 19x1 형태 => 입력층의 노드수가 19개! \n",
        "X_train_scaled[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.99508225, -0.43925252,  0.96350214, -0.65400354, -0.09779796,\n",
              "        0.32541085,  1.16743446, -1.19019364,  1.59286639,  0.72650531,\n",
              "       -0.72042294, -0.64249881, -0.79264136,  1.25707392, -0.83276144,\n",
              "       -0.83448511, -0.27868378, -0.00881575, -1.02585251])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfztkd7Xdw5M"
      },
      "source": [
        "# 모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMyQPCy5pV21"
      },
      "source": [
        "## 기본 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW-ny1Fud4ML"
      },
      "source": [
        "# import numpy as np\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "# import keras\n",
        "# import tensorflow as tf\n",
        "# import IPython\n",
        "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "# from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjzyQbLZwS4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7b773f-71e6-47a5-c5c2-4b3a45db0f23"
      },
      "source": [
        "!pip install -U keras-tuner\n",
        "import kerastuner as kt"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=f466ab00149a8f58bd7aac6b86150e65b99faddc9e432ce950e044049de4a33c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=c720a613befc282bc51ec3a6d77a5b3447c54b66dc2adcb354e13590b4cf7e49\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xblH5R2pnsG8"
      },
      "source": [
        "### 문제 6. np.unique를 이용해서 y_train의 Class 의 개수를 확인하고 입력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR709Nz8eCQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3058e656-1218-4a87-ae42-32f912bc8e18"
      },
      "source": [
        "print(np.unique(y_train))\n",
        "# 이진분류의 경우 class는 2개이지만, 출력층의 노드수 = 1 "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe3baua8j9aZ",
        "outputId": "e1000ed4-b643-4800-e0d3-69aaa0c44521"
      },
      "source": [
        "# 간단한 모델 만들어서 성능을 보기 !\n",
        "tf.random.set_seed(7)\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid')) # 00분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "\n",
        "model2.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "results = model2.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_test_scaled,y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "165/165 [==============================] - 4s 5ms/step - loss: 0.5132 - accuracy: 0.7363 - val_loss: 0.4490 - val_accuracy: 0.7901\n",
            "Epoch 2/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8004 - val_loss: 0.4463 - val_accuracy: 0.7929\n",
            "Epoch 3/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8054 - val_loss: 0.4462 - val_accuracy: 0.7901\n",
            "Epoch 4/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8055 - val_loss: 0.4446 - val_accuracy: 0.8043\n",
            "Epoch 5/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8068 - val_loss: 0.4512 - val_accuracy: 0.7947\n",
            "Epoch 6/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8190 - val_loss: 0.4517 - val_accuracy: 0.7833\n",
            "Epoch 7/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8217 - val_loss: 0.4517 - val_accuracy: 0.7952\n",
            "Epoch 8/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8269 - val_loss: 0.4539 - val_accuracy: 0.7861\n",
            "Epoch 9/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8320 - val_loss: 0.4569 - val_accuracy: 0.7833\n",
            "Epoch 10/10\n",
            "165/165 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8222 - val_loss: 0.4679 - val_accuracy: 0.7810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_916zS_xwRfj",
        "outputId": "80e0e585-a0ec-4509-87b3-13ac3588c7d7"
      },
      "source": [
        "model2.evaluate(X_test_scaled,  y_test, verbose=2) "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 - 0s - loss: 0.4679 - accuracy: 0.7810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4679003953933716, 0.7810011506080627]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKSycr4vKdcg",
        "outputId": "f7f05805-e9e7-4338-ed97-905652ccdd10"
      },
      "source": [
        "# 테스트셋 사용해서 결과 보기\n",
        "model2.evaluate(X_test_scaled,  y_test, verbose=2) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 - 0s - loss: 0.4679 - accuracy: 0.7810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4679003953933716, 0.7810011506080627]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOIeK9vgk7aS"
      },
      "source": [
        "파라미터 튜닝을 하기전에 간단히 임의로 넣어본 결과도 꽤 좋다. 이젠 GridSearchCV 를 사용해서 튜닝을 해보겠음!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH3zjICDpOpZ"
      },
      "source": [
        "## GridSearchCV 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K60WHG6gWYyG",
        "outputId": "87c2a7c6-f30f-4869-8d64-8032bdf85439"
      },
      "source": [
        "# 모델 만들기\n",
        "tf.random.set_seed(7)\n",
        "\n",
        "def model_builder(nodes=16, activation='relu'):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(nodes, activation=activation))\n",
        "  model.add(Dense(1, activation='sigmoid')) # 이진분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "\n",
        "  model.compile(optimizer='adam', \n",
        "                loss='binary_crossentropy', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# keras.wrapper를 활용하여 분류기를 만듭니다\n",
        "# keras wrapper가 필수이기 때문에,,\n",
        "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "model = KerasClassifier(build_fn=model_builder, verbose=0)\n",
        "\n",
        "# GridSearch\n",
        "batch_size = [50, 100, 300]\n",
        "epochs = [10, 20, 30]\n",
        "nodes = [64, 128, 256]\n",
        "activation = ['relu', 'sigmoid']\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs, nodes=nodes, activation=activation)\n",
        "\n",
        "\n",
        "# GridSearch CV를 만들기\n",
        "# 3*3*3*2 = 53개 조합, 개별 조합내에서 3 fold CV 53*3 = 162회, 3 fold의 결과 평균을 해당 조합의 퍼포먼스로 사용?(이부분 확인)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1, n_jobs=-1)\n",
        "grid_result = grid.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:  4.2min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5gClZlSyYeJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlDxZm42e95m",
        "outputId": "d009e0e3-9cb8-4831-d3cf-ceceb91b8eed"
      },
      "source": [
        "# 최적의 결과값을 낸 파라미터를 출력합니다\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")\n",
        "# Best: 0.8058399756749471 using {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 20, 'nodes': 64}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8060295780499777 using {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7948426405588785, Stdev: 0.00644115153404292 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7899127801259359, Stdev: 0.0020942986333580575 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7902920047442118, Stdev: 0.007508168041281857 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.788395901521047, Stdev: 0.0076738956855800415 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.7846037149429321, Stdev: 0.008312588942436687 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.7692453662554423, Stdev: 0.014922622845349521 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.785362164179484, Stdev: 0.007450459230759025 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7758816878000895, Stdev: 0.010343698049483629 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.7669700384140015, Stdev: 0.006894083521361518 with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.799582858880361, Stdev: 0.0038673006995410698 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7948426405588785, Stdev: 0.00689406275659277 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7910504539807638, Stdev: 0.009105204944671827 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.7984452048937479, Stdev: 0.001168813320088108 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.7899127801259359, Stdev: 0.007289495347677411 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.7825180093447367, Stdev: 0.007913802744965998 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.7925673127174377, Stdev: 0.007215119307939919 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7789154450098673, Stdev: 0.008985956075623868 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.7747440338134766, Stdev: 0.007673919249276483 with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.7967387239138285, Stdev: 0.001168813320088108 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7982556025187174, Stdev: 0.003359874768288879 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7992036541302999, Stdev: 0.0035064850828051925 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.7988244295120239, Stdev: 0.005383030959682136 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.8003413081169128, Stdev: 0.003968228986870748 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.7919984857241312, Stdev: 0.007831574407116121 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.7963594992955526, Stdev: 0.005631122016992988 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7910504539807638, Stdev: 0.000536304598351623 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.7838452657063802, Stdev: 0.0062484838467800514 with: {'activation': 'relu', 'batch_size': 300, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.8043230970700582, Stdev: 0.0023222183647484073 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.8026165962219238, Stdev: 0.003349173900978856 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7999620834986368, Stdev: 0.009057682815156976 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.8039438724517822, Stdev: 0.003359890465511094 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.7978763977686564, Stdev: 0.005383034458768887 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.8035646677017212, Stdev: 0.0022910580737759024 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.8060295780499777, Stdev: 0.001674597073829323 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7993932763735453, Stdev: 0.0042142798246717775 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.8056503534317017, Stdev: 0.002949605046186408 with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.799582858880361, Stdev: 0.002799567972849918 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7997724811236063, Stdev: 0.003968231834885048 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7974971731503805, Stdev: 0.009277315523624112 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.8007205128669739, Stdev: 0.003516728730436511 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.8024269938468933, Stdev: 0.009128859209534898 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.8014789621035258, Stdev: 0.001674597073829323 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.8018581668535868, Stdev: 0.0025579760285930077 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.7956010500590006, Stdev: 0.002094300432079147 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.799582858880361, Stdev: 0.005769843840242846 with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'nodes': 256}\n",
            "Means: 0.7882062792778015, Stdev: 0.0048341063920139885 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 10, 'nodes': 64}\n",
            "Means: 0.7895335555076599, Stdev: 0.004915230060256957 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 10, 'nodes': 128}\n",
            "Means: 0.7883959213892618, Stdev: 0.006698341053021006 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 10, 'nodes': 256}\n",
            "Means: 0.7935153444608053, Stdev: 0.00650224687856175 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 20, 'nodes': 64}\n",
            "Means: 0.7984452048937479, Stdev: 0.0050948101300933414 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 20, 'nodes': 128}\n",
            "Means: 0.8039438724517822, Stdev: 0.0016310698037157122 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 20, 'nodes': 256}\n",
            "Means: 0.7986348072687784, Stdev: 0.007299360708382721 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 30, 'nodes': 64}\n",
            "Means: 0.8026165962219238, Stdev: 0.004574271316601401 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 30, 'nodes': 128}\n",
            "Means: 0.8060295780499777, Stdev: 0.002457601234343974 with: {'activation': 'sigmoid', 'batch_size': 300, 'epochs': 30, 'nodes': 256}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVpkfckZoM4O"
      },
      "source": [
        "### 문항 7) 최적의 결과를 낸 파라미터와 결과값을 입력하시오.\n",
        "\n",
        "- batch_size\n",
        "- epochs\n",
        "- nodes\n",
        "- activation\n",
        "\n",
        "- 정답은 `[100, 100, 100], activation_name` 형태로 입력하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSvjGExCjvc_"
      },
      "source": [
        "'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'nodes': 128 가 최적으로 나왔다. 정확도는 약 0.80 \n",
        "\n",
        "이젠 Keras Tuner 를 사용한 파라미터 튜닝도 해보겠음!\n",
        "\n",
        "## Keras Tuner 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sICAonafRIG"
      },
      "source": [
        "# 모델 만들기\n",
        "\n",
        "def model_builder(hp):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  # Dense layer에서 노드 수를 조정(32-512)\n",
        "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
        "\n",
        "  model.add(Dense(units = hp_units, activation='relu'))\n",
        "  model.add(Dense(units = hp_units, activation='relu'))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid')) # 이진분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "\n",
        "  # Optimizer의 학습률(learning rate)을 조정[0.01, 0.001, 0.0001]합니다. \n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  # 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate = hp_learning_rate), \n",
        "                loss=keras.losses.BinaryCrossentropy(from_logits = True), \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pldUkyetfRKa"
      },
      "source": [
        "# 튜너를 인스턴스화하고 하이퍼 튜닝을 수행\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective = 'val_accuracy', \n",
        "                     max_epochs = 30, # The maximum number of epochs to train one model. model에 early stopping 써주는 것도 좋음\n",
        "                     factor = 3,\n",
        "                     directory = 'my_dir',\n",
        "                     project_name = 'intro_to_kt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mTmNvRkfRMe"
      },
      "source": [
        "# callback 정의 : 하이퍼 파라미터 검색을 실행하기 전에 모든 교육 단계가 끝날 때마다 교육 출력을 지우도록 콜백을 정의합니다.\n",
        "\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENk4-EMkfROz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33ee879-bf67-4704-edf4-3cb2399cb628"
      },
      "source": [
        "tuner.search(X_train_scaled, y_train, epochs = 30, batch_size=50, validation_data = (X_test_scaled,y_test), callbacks = [ClearTrainingOutput()])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "최적화된 Dense 노드 수 : {best_hps.get('units')} \n",
        "최적화된 Learning Rate : {best_hps.get('learning_rate')} \n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 62 Complete [00h 00m 01s]\n",
            "val_accuracy: 0.7986348271369934\n",
            "\n",
            "Best val_accuracy So Far: 0.8060295581817627\n",
            "Total elapsed time: 00h 01m 44s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "최적화된 Dense 노드 수 : 224 \n",
            "최적화된 Learning Rate : 0.001 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJzITjRromsc"
      },
      "source": [
        "### 문항 8) Keras 튜너를 활용하여 얻어낸 파라미터를 입력하시오. \n",
        "\n",
        "- 정답은 `[100, 100]` 형태로 입력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWztsOp66oXy",
        "outputId": "5fa3e7f5-e508-4546-8eb5-6d839de41ac9"
      },
      "source": [
        "X_train.shape[0]/50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105.48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQtipKllUBAy",
        "outputId": "cbb10f81-27ea-4615-a236-ee2c714a372a"
      },
      "source": [
        "# 찾은 파라미터들로 모델 만들어보기 (Dense 노드 수 : 416, Learning Rate : 0.01, batch_size : 100, epochs : 30)\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "tf.random.set_seed(1442)\n",
        "initializer = tf.keras.initializers.HeNormal()\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(best_hps.get('units'), \n",
        "                activation='relu', kernel_initializer=initializer,          \n",
        "                kernel_regularizer=regularizers.l2(0.01),    # L2 norm regularization\n",
        "                activity_regularizer=regularizers.l1(0.01))) # L1 norm regularization))\n",
        "model.add(Dense(best_hps.get('units'),\n",
        "                activation='relu', kernel_initializer=initializer,            \n",
        "                kernel_regularizer=regularizers.l2(0.01),    # L2 norm regularization\n",
        "                activity_regularizer=regularizers.l1(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid')) # 이진분류니까 노드수 1, 활성함수로는 시그모이드\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate = best_hps.get('learning_rate')), \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train_scaled, y_train, epochs=2, batch_size=50, validation_data=(X_test_scaled,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 10.0125 - accuracy: 0.7355 - val_loss: 5.8107 - val_accuracy: 0.7947\n",
            "Epoch 2/2\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 4.9895 - accuracy: 0.8000 - val_loss: 3.1786 - val_accuracy: 0.7929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt6EKBzUWI1E",
        "outputId": "0a94c009-1f2d-4861-e677-a9f05cdb0d85"
      },
      "source": [
        "# 테스트셋 사용해서 결과 보기\n",
        "model.evaluate(X_test_scaled,  y_test, verbose=2) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 - 0s - loss: 0.4942 - accuracy: 0.8020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49415111541748047, 0.8020477890968323]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAK2wZXOm8Tr"
      },
      "source": [
        "# 도전과제\n",
        "\n",
        "- Random Search 하이퍼 매개 변수 튜닝 구현해보세요.\n",
        "- hyperos 또는 hyperopts를 이용해서 Bayesian Optimiation tuning 수행 [(링크)](https://https://github.com/maxpumperla/hyperas)\n",
        "- 기존에 진행했던 강의&프로젝트 데이터셋을 하이퍼 파라미터로 조정해보세요. \n",
        "- Cifar100을 이용한다면 90% 이상 달성목표! [참고자료](https://paperswithcode.com/sota/image-classification-on-cifar-100)\n",
        "- MLP 모델을 forward 와 backward(학습까지)를 처음부터 구현할 수 있는가?\n",
        "- 케라스에서 MLP 모델을 구현하고 교차 검증(CV)을 통해 하이퍼 파라미터를 조정할 수 있는가?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DgncW3VL1N0"
      },
      "source": [
        "#### 1) Random Search 하이퍼 매개 변수 튜닝 구현해보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rufPv5tRBQqZ",
        "outputId": "0f8feef8-37bb-4fa7-bc21-7b38f6926471"
      },
      "source": [
        "X_train_scaled.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5274, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyWZXvlFm8Tr"
      },
      "source": [
        "def make_model_rscv(nodes=64, func='relu', rate=0.1, l2=0.01):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(nodes,\n",
        "                  activation='relu',\n",
        "                  input_dim=X_train_scaled.shape[1]))\n",
        "  model.add(Dense(256, activation=func))\n",
        "  model.add(Dropout(rate))\n",
        "  model.add(Dense(512, activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(l2)))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer = 'adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hzXfmLZNOLX"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPtNFkICNA44",
        "outputId": "bca24012-4dc3-4380-82d9-b16fa69ee55d"
      },
      "source": [
        "tf.random.set_seed(1442)\n",
        "param_grid = {'nodes': [32, 128, 256, 512],\n",
        "              'func':['tanh', 'relu', 'sigmoid', 'softmax'],\n",
        "              'rate':[0, 0.2, 0.5, 0.7],\n",
        "              'l2':[0.001, 0.005, 0.01, 0.05, 0.1]}\n",
        "\n",
        "model_rscv = KerasClassifier(build_fn=make_model_rscv, verbose=0)\n",
        "\n",
        "grid_rscv = RandomizedSearchCV(\n",
        "    estimator=model_rscv,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    verbose=3,\n",
        "    n_jobs=1,\n",
        "    random_state=12)\n",
        "\n",
        "grid_result_rscv = grid_rscv.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "[CV] rate=0.7, nodes=512, l2=0.005, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=512, l2=0.005, func=sigmoid, score=0.794, total=   1.0s\n",
            "[CV] rate=0.7, nodes=512, l2=0.005, func=sigmoid .....................\n",
            "[CV]  rate=0.7, nodes=512, l2=0.005, func=sigmoid, score=0.792, total=   0.9s\n",
            "[CV] rate=0.7, nodes=512, l2=0.005, func=sigmoid .....................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  rate=0.7, nodes=512, l2=0.005, func=sigmoid, score=0.792, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=relu .........................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=relu, score=0.783, total=   1.1s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=relu .........................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=relu, score=0.783, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=relu .........................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=relu, score=0.795, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.05, func=sigmoid, score=0.760, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.05, func=sigmoid, score=0.796, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.05, func=sigmoid, score=0.781, total=   0.9s\n",
            "[CV] rate=0.5, nodes=512, l2=0.001, func=sigmoid .....................\n",
            "[CV]  rate=0.5, nodes=512, l2=0.001, func=sigmoid, score=0.801, total=   0.9s\n",
            "[CV] rate=0.5, nodes=512, l2=0.001, func=sigmoid .....................\n",
            "[CV]  rate=0.5, nodes=512, l2=0.001, func=sigmoid, score=0.801, total=   0.9s\n",
            "[CV] rate=0.5, nodes=512, l2=0.001, func=sigmoid .....................\n",
            "[CV]  rate=0.5, nodes=512, l2=0.001, func=sigmoid, score=0.792, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.1, func=softmax .......................\n",
            "[CV]  rate=0.2, nodes=128, l2=0.1, func=softmax, score=0.735, total=   1.2s\n",
            "[CV] rate=0.2, nodes=128, l2=0.1, func=softmax .......................\n",
            "[CV]  rate=0.2, nodes=128, l2=0.1, func=softmax, score=0.726, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.1, func=softmax .......................\n",
            "[CV]  rate=0.2, nodes=128, l2=0.1, func=softmax, score=0.741, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.001, func=sigmoid .....................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.001, func=sigmoid, score=0.808, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.001, func=sigmoid .....................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.001, func=sigmoid, score=0.796, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.001, func=sigmoid .....................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.001, func=sigmoid, score=0.790, total=   0.9s\n",
            "[CV] rate=0.5, nodes=128, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.5, nodes=128, l2=0.05, func=sigmoid, score=0.757, total=   0.9s\n",
            "[CV] rate=0.5, nodes=128, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.5, nodes=128, l2=0.05, func=sigmoid, score=0.779, total=   1.2s\n",
            "[CV] rate=0.5, nodes=128, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.5, nodes=128, l2=0.05, func=sigmoid, score=0.791, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.001, func=tanh ..........................\n",
            "[CV]  rate=0, nodes=512, l2=0.001, func=tanh, score=0.798, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.001, func=tanh ..........................\n",
            "[CV]  rate=0, nodes=512, l2=0.001, func=tanh, score=0.799, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.001, func=tanh ..........................\n",
            "[CV]  rate=0, nodes=512, l2=0.001, func=tanh, score=0.788, total=   1.0s\n",
            "[CV] rate=0, nodes=512, l2=0.1, func=sigmoid .........................\n",
            "[CV]  rate=0, nodes=512, l2=0.1, func=sigmoid, score=0.750, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.1, func=sigmoid .........................\n",
            "[CV]  rate=0, nodes=512, l2=0.1, func=sigmoid, score=0.797, total=   0.9s\n",
            "[CV] rate=0, nodes=512, l2=0.1, func=sigmoid .........................\n",
            "[CV]  rate=0, nodes=512, l2=0.1, func=sigmoid, score=0.790, total=   0.9s\n",
            "[CV] rate=0.7, nodes=256, l2=0.1, func=sigmoid .......................\n",
            "[CV]  rate=0.7, nodes=256, l2=0.1, func=sigmoid, score=0.763, total=   0.9s\n",
            "[CV] rate=0.7, nodes=256, l2=0.1, func=sigmoid .......................\n",
            "[CV]  rate=0.7, nodes=256, l2=0.1, func=sigmoid, score=0.783, total=   1.2s\n",
            "[CV] rate=0.7, nodes=256, l2=0.1, func=sigmoid .......................\n",
            "[CV]  rate=0.7, nodes=256, l2=0.1, func=sigmoid, score=0.790, total=   0.9s\n",
            "[CV] rate=0, nodes=128, l2=0.05, func=tanh ...........................\n",
            "[CV]  rate=0, nodes=128, l2=0.05, func=tanh, score=0.786, total=   0.9s\n",
            "[CV] rate=0, nodes=128, l2=0.05, func=tanh ...........................\n",
            "[CV]  rate=0, nodes=128, l2=0.05, func=tanh, score=0.794, total=   0.9s\n",
            "[CV] rate=0, nodes=128, l2=0.05, func=tanh ...........................\n",
            "[CV]  rate=0, nodes=128, l2=0.05, func=tanh, score=0.786, total=   0.9s\n",
            "[CV] rate=0, nodes=32, l2=0.01, func=sigmoid .........................\n",
            "[CV]  rate=0, nodes=32, l2=0.01, func=sigmoid, score=0.774, total=   0.9s\n",
            "[CV] rate=0, nodes=32, l2=0.01, func=sigmoid .........................\n",
            "[CV]  rate=0, nodes=32, l2=0.01, func=sigmoid, score=0.745, total=   0.9s\n",
            "[CV] rate=0, nodes=32, l2=0.01, func=sigmoid .........................\n",
            "[CV]  rate=0, nodes=32, l2=0.01, func=sigmoid, score=0.787, total=   0.9s\n",
            "[CV] rate=0.5, nodes=128, l2=0.001, func=relu ........................\n",
            "[CV]  rate=0.5, nodes=128, l2=0.001, func=relu, score=0.800, total=   0.9s\n",
            "[CV] rate=0.5, nodes=128, l2=0.001, func=relu ........................\n",
            "[CV]  rate=0.5, nodes=128, l2=0.001, func=relu, score=0.794, total=   1.2s\n",
            "[CV] rate=0.5, nodes=128, l2=0.001, func=relu ........................\n",
            "[CV]  rate=0.5, nodes=128, l2=0.001, func=relu, score=0.792, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.005, func=tanh ........................\n",
            "[CV]  rate=0.2, nodes=128, l2=0.005, func=tanh, score=0.794, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.005, func=tanh ........................\n",
            "[CV]  rate=0.2, nodes=128, l2=0.005, func=tanh, score=0.800, total=   0.9s\n",
            "[CV] rate=0.2, nodes=128, l2=0.005, func=tanh ........................\n",
            "[CV]  rate=0.2, nodes=128, l2=0.005, func=tanh, score=0.787, total=   0.9s\n",
            "[CV] rate=0.7, nodes=512, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.7, nodes=512, l2=0.05, func=sigmoid, score=0.795, total=   0.9s\n",
            "[CV] rate=0.7, nodes=512, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.7, nodes=512, l2=0.05, func=sigmoid, score=0.797, total=   0.9s\n",
            "[CV] rate=0.7, nodes=512, l2=0.05, func=sigmoid ......................\n",
            "[CV]  rate=0.7, nodes=512, l2=0.05, func=sigmoid, score=0.793, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=tanh .........................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=tanh, score=0.786, total=   1.1s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=tanh .........................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=tanh, score=0.784, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.001, func=tanh .........................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.001, func=tanh, score=0.786, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.01, func=tanh .........................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.01, func=tanh, score=0.800, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.01, func=tanh .........................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.01, func=tanh, score=0.798, total=   0.9s\n",
            "[CV] rate=0.2, nodes=256, l2=0.01, func=tanh .........................\n",
            "[CV]  rate=0.2, nodes=256, l2=0.01, func=tanh, score=0.795, total=   0.9s\n",
            "[CV] rate=0.2, nodes=512, l2=0.05, func=softmax ......................\n",
            "[CV]  rate=0.2, nodes=512, l2=0.05, func=softmax, score=0.735, total=   0.9s\n",
            "[CV] rate=0.2, nodes=512, l2=0.05, func=softmax ......................\n",
            "[CV]  rate=0.2, nodes=512, l2=0.05, func=softmax, score=0.726, total=   1.0s\n",
            "[CV] rate=0.2, nodes=512, l2=0.05, func=softmax ......................\n",
            "[CV]  rate=0.2, nodes=512, l2=0.05, func=softmax, score=0.741, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.005, func=softmax ......................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.005, func=softmax, score=0.735, total=   1.2s\n",
            "[CV] rate=0.2, nodes=32, l2=0.005, func=softmax ......................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.005, func=softmax, score=0.726, total=   0.9s\n",
            "[CV] rate=0.2, nodes=32, l2=0.005, func=softmax ......................\n",
            "[CV]  rate=0.2, nodes=32, l2=0.005, func=softmax, score=0.741, total=   0.9s\n",
            "[CV] rate=0.7, nodes=32, l2=0.1, func=tanh ...........................\n",
            "[CV]  rate=0.7, nodes=32, l2=0.1, func=tanh, score=0.794, total=   0.9s\n",
            "[CV] rate=0.7, nodes=32, l2=0.1, func=tanh ...........................\n",
            "[CV]  rate=0.7, nodes=32, l2=0.1, func=tanh, score=0.779, total=   0.9s\n",
            "[CV] rate=0.7, nodes=32, l2=0.1, func=tanh ...........................\n",
            "[CV]  rate=0.7, nodes=32, l2=0.1, func=tanh, score=0.792, total=   0.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   57.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "hANVaPFeP-59",
        "outputId": "423a4ad3-df10-43e8-8bbd-4da1bde3c9e2"
      },
      "source": [
        "rs = pd.DataFrame(grid_result_rscv.cv_results_).sort_values(by='rank_test_score').head()\n",
        "rs.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>16</th>\n",
              "      <th>12</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean_fit_time</th>\n",
              "      <td>0.792805</td>\n",
              "      <td>0.794649</td>\n",
              "      <td>0.796603</td>\n",
              "      <td>0.880406</td>\n",
              "      <td>0.821169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_fit_time</th>\n",
              "      <td>0.0110927</td>\n",
              "      <td>0.0124274</td>\n",
              "      <td>0.00341146</td>\n",
              "      <td>0.124761</td>\n",
              "      <td>0.0113597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_score_time</th>\n",
              "      <td>0.11431</td>\n",
              "      <td>0.112394</td>\n",
              "      <td>0.109338</td>\n",
              "      <td>0.110921</td>\n",
              "      <td>0.116589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_score_time</th>\n",
              "      <td>0.00230824</td>\n",
              "      <td>0.000843507</td>\n",
              "      <td>0.000459571</td>\n",
              "      <td>0.00400837</td>\n",
              "      <td>0.00647866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_rate</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_nodes</th>\n",
              "      <td>512</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_l2</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_func</th>\n",
              "      <td>sigmoid</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>tanh</td>\n",
              "      <td>relu</td>\n",
              "      <td>tanh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params</th>\n",
              "      <td>{'rate': 0.5, 'nodes': 512, 'l2': 0.001, 'func...</td>\n",
              "      <td>{'rate': 0.2, 'nodes': 256, 'l2': 0.001, 'func...</td>\n",
              "      <td>{'rate': 0.2, 'nodes': 256, 'l2': 0.01, 'func'...</td>\n",
              "      <td>{'rate': 0.5, 'nodes': 128, 'l2': 0.001, 'func...</td>\n",
              "      <td>{'rate': 0, 'nodes': 512, 'l2': 0.001, 'func':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split0_test_score</th>\n",
              "      <td>0.801479</td>\n",
              "      <td>0.807736</td>\n",
              "      <td>0.799772</td>\n",
              "      <td>0.800341</td>\n",
              "      <td>0.798066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split1_test_score</th>\n",
              "      <td>0.80091</td>\n",
              "      <td>0.796359</td>\n",
              "      <td>0.798066</td>\n",
              "      <td>0.794084</td>\n",
              "      <td>0.799204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split2_test_score</th>\n",
              "      <td>0.792378</td>\n",
              "      <td>0.789534</td>\n",
              "      <td>0.794653</td>\n",
              "      <td>0.791809</td>\n",
              "      <td>0.788396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_score</th>\n",
              "      <td>0.798256</td>\n",
              "      <td>0.797876</td>\n",
              "      <td>0.797497</td>\n",
              "      <td>0.795411</td>\n",
              "      <td>0.795222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_test_score</th>\n",
              "      <td>0.00416278</td>\n",
              "      <td>0.00750815</td>\n",
              "      <td>0.00212836</td>\n",
              "      <td>0.00360756</td>\n",
              "      <td>0.00484896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rank_test_score</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                   3  ...                                                  7\n",
              "mean_fit_time                                               0.792805  ...                                           0.821169\n",
              "std_fit_time                                               0.0110927  ...                                          0.0113597\n",
              "mean_score_time                                              0.11431  ...                                           0.116589\n",
              "std_score_time                                            0.00230824  ...                                         0.00647866\n",
              "param_rate                                                       0.5  ...                                                  0\n",
              "param_nodes                                                      512  ...                                                512\n",
              "param_l2                                                       0.001  ...                                              0.001\n",
              "param_func                                                   sigmoid  ...                                               tanh\n",
              "params             {'rate': 0.5, 'nodes': 512, 'l2': 0.001, 'func...  ...  {'rate': 0, 'nodes': 512, 'l2': 0.001, 'func':...\n",
              "split0_test_score                                           0.801479  ...                                           0.798066\n",
              "split1_test_score                                            0.80091  ...                                           0.799204\n",
              "split2_test_score                                           0.792378  ...                                           0.788396\n",
              "mean_test_score                                             0.798256  ...                                           0.795222\n",
              "std_test_score                                            0.00416278  ...                                         0.00484896\n",
              "rank_test_score                                                    1  ...                                                  5\n",
              "\n",
              "[15 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-pnUspQsRNX"
      },
      "source": [
        "RandomizedSearchCV를 썼을 때의 결과도 GridSearchCV를 사용했을 때와 다르게 나왔다. 하지만 시간 때문에 RandomizedSearchCV의 iter수를 탐색 영역에 비해서 작게 설정했기 때문에 위 결과가 최선의 결과라고 할 수는 없다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nozG7olCF3tf"
      },
      "source": [
        "### 2) hyperos 또는 hyperopts를 이용해서 Bayesian Optimiation tuning 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1IAENisF7iZ"
      },
      "source": [
        "!pip install hyperas\n",
        "!pip install category_encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVCZNESFHGLP"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from category_encoders import OrdinalEncoder"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD3BnPsSPxFN"
      },
      "source": [
        "# hyperas 를 colab에서 사용하려고 하면, 노트북을 찾지 못해서 코드가 돌아가지 않는다.\n",
        "# from hyperopt import Trials, Trials class에서 경로를 받아서 결과를 기록하는 것 같은데\n",
        "# 해당 부분이 돌아가지 않음, colab을 지금 돌아가고 있는 환경에 monunt해야 하는 것 같음\n",
        "# 노트북이 내 google driver에 저장되어 있어야함\n",
        "# see: https://towardsdatascience.com/keras-hyperparameter-tuning-in-google-colab-using-hyperas-624fa4bbf673\n",
        "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='ds-cs-N424a_.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('ds-cs-N424a_.ipynb')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gywB403H8bj",
        "outputId": "3534de76-efa2-46a3-f930-58f80a3c232b"
      },
      "source": [
        "\n",
        "\n",
        "# data load 부분을 함수로 다 구현해야함..?\n",
        "def data():\n",
        "\n",
        "  df = pd.read_csv('TelcomCustomer.csv')\n",
        "  df['TotalCharges'].replace(' ', np.nan, inplace=True)\n",
        "  df.dropna(axis=0, inplace=True)\n",
        "  df = df.drop(columns='customerID')\n",
        "  # Attributing No internet service to No\n",
        "  no_internet_feats = [ 'TechSupport','OnlineBackup', 'DeviceProtection','StreamingTV',\n",
        "                  'OnlineSecurity','StreamingMovies']\n",
        "\n",
        "  for i in no_internet_feats:\n",
        "    df[i] = df[i].replace({'No internet service':'No'})\n",
        "\n",
        "  # Attributing No phone service to No\n",
        "  df['MultipleLines']=df['MultipleLines'].replace({'No phone service':'No'})\n",
        "\n",
        "  # Attributing No phone service to No\n",
        "  df['SeniorCitizen']=df['SeniorCitizen'].replace({0:'No',\n",
        "                                                  1:'Yes'})\n",
        "  encoder = OrdinalEncoder()\n",
        "  df_encoded = encoder.fit_transform(df)\n",
        "\n",
        "  # 타겟을 0과 1로 바꿔주기\n",
        "  df_encoded['Churn'] = df_encoded['Churn'].replace({1: 0, 2: 1})\n",
        "  df_encoded['Churn'].value_counts()\n",
        "\n",
        "  train, test = train_test_split(df_encoded, stratify=df_encoded['Churn'], random_state=1, test_size=0.25)\n",
        "\n",
        "  target = 'Churn'\n",
        "  features = df_encoded.drop(columns=[target]).columns\n",
        "\n",
        "  X_train = train[features]\n",
        "  X_test = test[features]\n",
        "\n",
        "  y_train = train[target]\n",
        "  y_test = test[target]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  X_train_ = X_train_scaled\n",
        "  X_test_ = X_test_scaled\n",
        "  y_train_ = y_train\n",
        "  y_test_ = y_test\n",
        "\n",
        "  return X_train_, y_train_, X_test_, y_test_\n",
        "\n",
        "def create_model(X_train_, y_train_, X_test_, y_test_):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense({{choice([256, 512, 1024])}}, input_shape=(19,)) ) # {{}}사이에 넣고 choice\n",
        "  model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "  # model.add(Dropout({{uniform(0, 1)}})) # Dropout 조절가능\n",
        "  model.add(Dense({{choice([256, 512, 1024])}}))\n",
        "  model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "  model.add(Dense(1, activation='sigmoid')) # 2진분류\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                metrics=['accuracy'],\n",
        "                optimizer={{choice(['adam', 'sgd'])}})\n",
        "\n",
        "  result = model.fit(X_train_, y_train_,\n",
        "                     batch_size= {{choice([32,64])}},\n",
        "                     epochs=3,\n",
        "                     verbose=2,\n",
        "                     validation_split=0.2)\n",
        "  \n",
        "  #get the highest validation accuracy of the training epochs\n",
        "  #아마도 traing set 속에서 validation_split 0.2퍼 하고 acc amax를 저장하는 것 같음\n",
        "  # print(result.history)\n",
        "  validation_acc = np.amax(result.history['val_accuracy']) # 공식 깃 예제에 잘못되있음,, val_acc 아님,,\n",
        "  print('Best validation acc of epoch:', validation_acc)\n",
        "  return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
        "  \n",
        "best_run, best_model = optim.minimize(model=create_model,\n",
        "                                          data=data,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          max_evals=5,\n",
        "                                          trials=Trials(),\n",
        "                                          notebook_name='ds-cs-N424a_'\n",
        "                                          )\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    from google.colab import files\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas as pd\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from category_encoders import OrdinalEncoder\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.preprocessing import StandardScaler\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import kerastuner as kt\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras import regularizers\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import RandomizedSearchCV\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pandas as pd\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from math import sqrt\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
            "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dense_1': hp.choice('Dense_1', [256, 512, 1024]),\n",
            "        'Activation_1': hp.choice('Activation_1', ['relu', 'sigmoid']),\n",
            "        'optimizer': hp.choice('optimizer', ['adam', 'sgd']),\n",
            "        'batch_size': hp.choice('batch_size', [32,64]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "   1: \n",
            "   2: \n",
            "   3: df = pd.read_csv('TelcomCustomer.csv')\n",
            "   4: df['TotalCharges'].replace(' ', np.nan, inplace=True)\n",
            "   5: df.dropna(axis=0, inplace=True)\n",
            "   6: df = df.drop(columns='customerID')\n",
            "   7: # Attributing No internet service to No\n",
            "   8: no_internet_feats = [ 'TechSupport','OnlineBackup', 'DeviceProtection','StreamingTV',\n",
            "   9:                 'OnlineSecurity','StreamingMovies']\n",
            "  10: \n",
            "  11: for i in no_internet_feats:\n",
            "  12:   df[i] = df[i].replace({'No internet service':'No'})\n",
            "  13: \n",
            "  14: # Attributing No phone service to No\n",
            "  15: df['MultipleLines']=df['MultipleLines'].replace({'No phone service':'No'})\n",
            "  16: \n",
            "  17: # Attributing No phone service to No\n",
            "  18: df['SeniorCitizen']=df['SeniorCitizen'].replace({0:'No',\n",
            "  19:                                                 1:'Yes'})\n",
            "  20: encoder = OrdinalEncoder()\n",
            "  21: df_encoded = encoder.fit_transform(df)\n",
            "  22: \n",
            "  23: # 타겟을 0과 1로 바꿔주기\n",
            "  24: df_encoded['Churn'] = df_encoded['Churn'].replace({1: 0, 2: 1})\n",
            "  25: df_encoded['Churn'].value_counts()\n",
            "  26: \n",
            "  27: train, test = train_test_split(df_encoded, stratify=df_encoded['Churn'], random_state=1, test_size=0.25)\n",
            "  28: \n",
            "  29: target = 'Churn'\n",
            "  30: features = df_encoded.drop(columns=[target]).columns\n",
            "  31: \n",
            "  32: X_train = train[features]\n",
            "  33: X_test = test[features]\n",
            "  34: \n",
            "  35: y_train = train[target]\n",
            "  36: y_test = test[target]\n",
            "  37: \n",
            "  38: scaler = StandardScaler()\n",
            "  39: X_train_scaled = scaler.fit_transform(X_train)\n",
            "  40: X_test_scaled = scaler.transform(X_test)\n",
            "  41: \n",
            "  42: X_train_ = X_train_scaled\n",
            "  43: X_test_ = X_test_scaled\n",
            "  44: y_train_ = y_train\n",
            "  45: y_test_ = y_test\n",
            "  46: \n",
            "  47: \n",
            "  48: \n",
            "  49: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3: \n",
            "   4:   model = Sequential()\n",
            "   5:   model.add(Dense(space['Dense'], input_shape=(19,)) ) # {{}}사이에 넣고 choice\n",
            "   6:   model.add(Activation(space['Activation']))\n",
            "   7:   # model.add(Dropout(space['Dropout'])) # Dropout 조절가능\n",
            "   8:   model.add(Dense(space['Dense_1']))\n",
            "   9:   model.add(Activation(space['Activation_1']))\n",
            "  10:   model.add(Dense(1, activation='sigmoid')) # 2진분류\n",
            "  11: \n",
            "  12:   model.compile(loss='binary_crossentropy',\n",
            "  13:                 metrics=['accuracy'],\n",
            "  14:                 optimizer=space['optimizer'])\n",
            "  15: \n",
            "  16:   result = model.fit(X_train_, y_train_,\n",
            "  17:                      batch_size= space['batch_size'],\n",
            "  18:                      epochs=3,\n",
            "  19:                      verbose=2,\n",
            "  20:                      validation_split=0.2)\n",
            "  21:   \n",
            "  22:   #get the highest validation accuracy of the training epochs\n",
            "  23:   #아마도 traing set 속에서 validation_split 0.2퍼 하고 acc amax를 저장하는 것 같음\n",
            "  24:   # print(result.history)\n",
            "  25:   validation_acc = np.amax(result.history['val_accuracy']) \n",
            "  26:   print('Best validation acc of epoch:', validation_acc)\n",
            "  27:   return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
            "  28: \n",
            "Epoch 1/3\n",
            "66/66 - 1s - loss: 0.4712 - accuracy: 0.7575 - val_loss: 0.4228 - val_accuracy: 0.7943\n",
            "\n",
            "Epoch 2/3\n",
            "66/66 - 0s - loss: 0.4106 - accuracy: 0.7992 - val_loss: 0.4270 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 3/3\n",
            "66/66 - 0s - loss: 0.4010 - accuracy: 0.8085 - val_loss: 0.4267 - val_accuracy: 0.7991\n",
            "\n",
            "Best validation acc of epoch:\n",
            "0.800000011920929\n",
            "Epoch 1/3\n",
            "132/132 - 1s - loss: 0.4379 - accuracy: 0.7836 - val_loss: 0.4279 - val_accuracy: 0.7962\n",
            "\n",
            "Epoch 2/3\n",
            "132/132 - 0s - loss: 0.4068 - accuracy: 0.8080 - val_loss: 0.4308 - val_accuracy: 0.8019\n",
            "\n",
            "Epoch 3/3\n",
            "132/132 - 0s - loss: 0.3969 - accuracy: 0.8154 - val_loss: 0.4529 - val_accuracy: 0.7886\n",
            "\n",
            "Best validation acc of epoch:\n",
            "0.8018957376480103\n",
            "Epoch 1/3\n",
            "132/132 - 1s - loss: 0.5712 - accuracy: 0.7324 - val_loss: 0.5463 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 2/3\n",
            "132/132 - 0s - loss: 0.5414 - accuracy: 0.7326 - val_loss: 0.5284 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 3/3\n",
            "132/132 - 0s - loss: 0.5174 - accuracy: 0.7376 - val_loss: 0.4973 - val_accuracy: 0.7412\n",
            "\n",
            "Best validation acc of epoch:\n",
            "0.7412322163581848\n",
            "Epoch 1/3\n",
            "66/66 - 1s - loss: 0.5819 - accuracy: 0.7248 - val_loss: 0.5627 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 2/3\n",
            "66/66 - 0s - loss: 0.5659 - accuracy: 0.7324 - val_loss: 0.5542 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 3/3\n",
            "66/66 - 0s - loss: 0.5580 - accuracy: 0.7324 - val_loss: 0.5483 - val_accuracy: 0.7412\n",
            "\n",
            "Best validation acc of epoch:\n",
            "0.7412322163581848\n",
            "Epoch 1/3\n",
            "132/132 - 1s - loss: 0.5797 - accuracy: 0.7281 - val_loss: 0.5646 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 2/3\n",
            "132/132 - 0s - loss: 0.5608 - accuracy: 0.7324 - val_loss: 0.5426 - val_accuracy: 0.7412\n",
            "\n",
            "Epoch 3/3\n",
            "132/132 - 0s - loss: 0.5447 - accuracy: 0.7324 - val_loss: 0.5320 - val_accuracy: 0.7412\n",
            "\n",
            "Best validation acc of epoch:\n",
            "0.7412322163581848\n",
            "100%|██████████| 5/5 [00:07<00:00,  1.40s/it, best loss: -0.8018957376480103]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVbYG7HeYgWJ",
        "outputId": "9c11d6bf-407e-4523-be55-cb6b0286d0d1"
      },
      "source": [
        "best_run, best_model # chioce index 번호로 저장되어 있음"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Activation': 0,\n",
              "  'Activation_1': 0,\n",
              "  'Dense': 1,\n",
              "  'Dense_1': 2,\n",
              "  'Dropout': 0.9128294469805703,\n",
              "  'batch_size': 0,\n",
              "  'optimizer': 0},\n",
              " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f03d06c8c90>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AVtEA7oYxBD",
        "outputId": "a954c988-0c82-4460-8e31-6e35900ed019"
      },
      "source": [
        "_, _, X_test, Y_test = data() # 근데 이렇게 하면 다시 섞일거 같은데 시드가 1이면 항상 같은가?\n",
        "best_model.evaluate(X_test, Y_test)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4710337221622467, 0.8003413081169128]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtDfDdLtZ4Py"
      },
      "source": [
        "***Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization!!!!***\n",
        "\n",
        "매우 간단하다는 말에 속아 일단 시작했다.(우여곡절이 있었지만 아무튼 한두시간 정도에 간단하게 적용해볼 수 있었으니까 Simple인가,,,?). 구체적으로 어떻게 동작하는지는 좀더 문서들을 읽어봐야겠지만, 매우 빠르게 학습이 진행되는 느낌은 있다(그래서 베이지안인가?). 하지만 keras tuner가 더 쉬운거 같은데,,  \n",
        "원하는 코드들을 함수형태로 다 만든다음에 블럭처럼,? optim.minimize 속에 넣어주고, trials=Trials() 이부분을 통해서 새로운 .py를 알아서 만들어서, 그 속에서 돌아가는 것처럼 생각된다. print를 보면 노트북 속의 코드들이 전부 찍혀 나오는 것을 볼 수 있다.  \n",
        "아무튼 적당히 코드를 적용하게 만들어 두었으니 나중에 써먹을 수 있을 것 같다. 일단 장점과 좀더 구체적인 동작방식을 알아야 할 것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhRCzzMRbynf"
      },
      "source": [
        "### 3) Clfar 100을 이용한 이전 코드를 튜닝\n",
        "---\n",
        "이부분은 어제 도전과제에서 조금 해본 부분이 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leCxISKHb9aa"
      },
      "source": [
        "# 그냥 런타임 초기화 할것.\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from keras.applications import VGG19, ResNet50\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from kerastuner.tuners import RandomSearch, Hyperband\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4leLQ9FdRAf",
        "outputId": "3aec4e82-f7bd-498a-e690-d7b5eb8a1736"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFJid4bGd8N_"
      },
      "source": [
        "# nomalize\n",
        "X_train = X_train.astype('float32') / 255.0 - 0.5\n",
        "X_test = X_test.astype('float32') / 255.0 - 0.5\n",
        "\n",
        "\n",
        "# validation set 분리\n",
        "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=.2)\n",
        "\n",
        "# one hot encording target value\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKnTGE1Qents"
      },
      "source": [
        "def \n",
        "# VGG 19는 pre-define된 convolution layer\n",
        "base_model_1 = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3), classes=y_train.shape[1])\n",
        "\n",
        "model_1= Sequential()\n",
        "model_1.add(base_model_1) \n",
        "model_1.add(Flatten()) \n",
        "\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(512,activation=('relu'))) \n",
        "model_1.add(Dense(256,activation=('relu'))) \n",
        "# model_1.add(Dropout(.3)) #Adding a dropout layer that will randomly drop 30% of the weights\n",
        "model_1.add(Dense(128,activation=('relu')))\n",
        "# model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(num_classes,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcUNGozye0Ru"
      },
      "source": [
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model_1.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(X_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYyJvyg9L8VV"
      },
      "source": [
        "### 4) MLP 모델을 forward 와 backward(학습까지)를 처음부터 구현할 수 있는가?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQA8OhW3WCaH"
      },
      "source": [
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjYzDdX2L88s"
      },
      "source": [
        "class MLP:\n",
        "  def __init__(self, input_nodes, hidden_nodes, output_nodes, lr):\n",
        "    \"\"\"\n",
        "    MLP 클래스의 생성자 함수입니다.\n",
        "    \n",
        "    Args:\n",
        "        input_nodes: 입력층의 노드 개수\n",
        "        hidden_nodes: 은닉층의 노드 개수\n",
        "        output_nodes: 출력층의 노드 개수\n",
        "        lr: 학습률\n",
        "    \"\"\"\n",
        "    self.input_nodes = input_nodes\n",
        "    self.hidden_nodes = hidden_nodes\n",
        "    self.output_nodes = output_nodes\n",
        "    self.lr = lr\n",
        "\n",
        "    self.w_ih = np.random.normal(0,\n",
        "                                 sqrt(2/(self.input_nodes + self.hidden_nodes)),\n",
        "                                 (self.input_nodes, self.hidden_nodes))\n",
        "    self.w_ho = np.random.normal(0,\n",
        "                                 sqrt(2/(self.hidden_nodes + self.output_nodes)),\n",
        "                                 (self.hidden_nodes, self.output_nodes))\n",
        "    \n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    \"\"\"\n",
        "    활성화 함수로 사용할 sigmoid 함수입니다.\n",
        "    \"\"\"\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "\n",
        "  def fit(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    모델을 학습합니다.\n",
        "\n",
        "    Args:\n",
        "        X_train(2차원 numpy.array, float): 학습할 데이터\n",
        "        y_train(2차원 numpy.array, float): 학습할 데이터의 타겟\n",
        "    # \"\"\"\n",
        "    self.inputs = X_train\n",
        "    self.targets = y_train\n",
        "    return self.forward('train')\n",
        "\n",
        "\n",
        "  def forward(self, filter):\n",
        "    if filter == 'train':\n",
        "      self.h = np.dot(self.inputs, self.w_ih)\n",
        "      self.H = self.sigmoid(self.h)\n",
        "\n",
        "      self.y = np.dot(self.H, self.w_ho)\n",
        "      self.Y = self.sigmoid(self.y)\n",
        "\n",
        "      return self.backward()\n",
        "\n",
        "    elif filter == 'pred':\n",
        "      self.h = np.dot(self.inputs, self.w_ih)\n",
        "      self.H = self.sigmoid(self.h)\n",
        "\n",
        "      self.y = np.dot(self.H, self.w_ho)\n",
        "      self.Y = self.sigmoid(self.y)\n",
        "      return self.Y\n",
        "\n",
        "  # 가중치 업데이트\n",
        "  def backward(self):\n",
        "    self.o_error = -(self.targets-self.Y)\n",
        "    self.o_delta = self.o_error * (self.Y * (1 - self.Y))\n",
        "\n",
        "    self.h_error = self.o_delta.dot(self.w_ho.T)\n",
        "    self.h_delta = self.h_error * (self.y * (1 - self.y))\n",
        "\n",
        "    self.w_ih = self.w_ih - self.lr*self.inputs.T.dot(self.h_delta)\n",
        "    self.w_ho = self.w_ho - self.lr*self.H.T.dot(self.o_delta)\n",
        "\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    \"\"\"\n",
        "    타겟을 예측하는 함수입니다.\n",
        "    \"\"\"\n",
        "    self.inputs = X_test\n",
        "\n",
        "    result = self.forward('pred')\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw3nAz9cUbu1"
      },
      "source": [
        "a = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "b = np.array([[10], [20], [30]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8jAtx6Yjmk5"
      },
      "source": [
        "mlp = MLP(2, 3, 1, 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcxbC2VblP3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59be9f7b-3998-4119-cfc2-250ce9234341"
      },
      "source": [
        "# 초기 가중치\n",
        "print(mlp.w_ih)\n",
        "print(mlp.w_ho)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.6125871   0.77772355  0.12272781]\n",
            " [-0.10692782 -0.581819   -0.54900859]]\n",
            "[[-0.25205016]\n",
            " [-0.14311679]\n",
            " [ 0.04712651]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqVk4i74k1Gy"
      },
      "source": [
        "mlp.fit(a, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M5qKLx8lUSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f219e1-0aa2-4515-c754-851982e0750b"
      },
      "source": [
        "# 학습 후 가중치\n",
        "print(mlp.w_ih)\n",
        "print(mlp.w_ho)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.59924549  0.78529906  0.12023329]\n",
            " [-0.08978862 -0.57208718 -0.55221316]]\n",
            "[[-0.23847518]\n",
            " [-0.06502462]\n",
            " [ 0.06509709]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIlISxqXk-yj"
      },
      "source": [
        "c = np.array([[10, 12]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sywyf9FGk4tN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbea891-8ea7-45f2-cf38-7926f24edf6e"
      },
      "source": [
        "mlp.predict(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48817742]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pVrYix9CDn_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKzgp-brlkU5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}